The INSTALL document for $BIOS
==============================

This INSTALL document is about building and installing prerequisites
from source and/or as resulting packages for the Eaton $BIOS core project.

Also keep in mind that the $BIOS core project auto-configuration procdure
relies on `pkg-config` information (including the library versions), so
it should be available (as the installed subsystem of the OS as well as
the *.pc files as part of packaged or privately-built prerequisite software).

To ease copy-pasting, the example commands in this document are prefixed
with a colon+semicolon prompt `:;` which is an empty command for shell
interpreters (unlike the dollar `$` or hash `#` signs which have their
meaning for shells and can adversely influence copy-pasted commands).



Get the source
--------------
If you are reading this file, you probably have some version of the
$BIOS core project source code already. It might not be the most fresh
version, however, so to stay on the bleeding edge of development you
might want to clone the source-code repository onto your development
system.

Checkout of the main upstream repository itself is more of interest to
those responsible for building the current project state into binaries
for validation or redistribution. Code should not be "pushed" into this
repository directly except after review by the source code gate-keepers.
The upstream $BIOS core project repository can be cloned with the command
below (proper access to the project infrastructure server is required)
over SSH (keys should be uploaded to the user's Stash account first):
----
:; git clone ssh://git@stash.mbt.lab.etn.com:7999/bios/core.git
----
...or over HTTP (plaintext password may be required which is not good, and
special characters may need URL percent-encoding which is inconvenient):
----
:; git clone http://E1234567:MyPass@stash.mbt.lab.etn.com/scm/bios/core.git
----

The project workflow for actual development implies that one should first
"fork" the upstream repository in the Stash web-interface into a private
namespace (named like E1234567 below) with automatic application of updates
from the upstream repo, then `git clone` this private repository onto his
or her PC for actual coding; it is convenient to also register the common
upstream repository as such, to facilitate comparisons and updates which
were not resolved automatically (i.e. several changes applied to the same
area in the tracked files and possibly conflicting):
----
:; git clone \
     ssh://git@stash.mbt.lab.etn.com:7999/~E1234567/core.git core-myfork && \
   cd core-myfork/ && \
   git remote add \
     upstream ssh://git@stash.mbt.lab.etn.com:7999/bios/core.git && \
   git fetch --all --tags


### Verify the local workspace (checked-out and available branches):
:; git branch -a

* master
  remotes/origin/HEAD -> origin/master
  remotes/origin/master
  remotes/upstream/master
----

Then the developer may create branches for working on individual issues
and when some work is done -- push the code back to his personal fork
on Stash for common review like this:
----
:; git add changedfiles* && git commit -m 'Meaningful text' && git push
----
...and afterwards use the Stash web-interface to initiate a pull-request
for code review and ultimate merge of his or her changes into the common
codebase by the gate-keepers.



Configure package repositories of pre-built prerequisites for the project
-------------------------------------------------------------------------
Currently $BIOS relies on some Linux-specific features, so the code is
not expected to compile and work in other operating system platforms,
at least not in its entirety. It is not currently a goal of the core
development team to support deployment on more platforms than we can
handle and validate ourselves. Current target devices will be ARM boxes
running an embedded Linux distribution, and the developer workstations
run an assortment of recent PC Linux distributions. The project team's
infrastructure services include an Open Build Service (OBS)-based server
to automatically check out and rebuild the packages with some of our own
and third-party code relevant for our project for some platforms that
are of interest to ourselves.

Alternately, it is possible to rebuild and install the needed packages
from latest sources, as will be detailed below. In particular, many of
these are either absent or critically too-old in the general OS package
repositories, and some projects are being developed in cooperation with
our $BIOS project, so it is essential to use their bleeding-edge as well.

The software packages pre-built for the project can be located in our OBS
build-results repositories, including the following Linux OS releases:

 * http://obs.mbt.lab.etn.com:82/Pool:/master/Debian_8.0/
 * http://obs.roz.lab.etn.com:82/Pool:/master/Debian_8.0/
 * http://obs.roz.lab.etn.com:82/Pool:/master/CentOS_7.0/
 * http://obs.roz.lab.etn.com:82/Pool:/master/openSUSE_13.1/

These packages include such build and/or runtime dependencies as
libvariant, iproute2, mariadb, zeromq and so on.

[NOTE]
*NOTE*: See the document 'INSTALL-referenceOS-debian8' (or its derivative
product 'link:INSTALL-referenceOS-debian8.html[]') for a how-to detailing
the reference installation of a Debian 8 x86_64 (VM) to build this project.

Installing an APT package source for Debian 8.0
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
One of the Linux OSes supported automatically by our OBS service is
Debian 8.0 for "x86_64" and "armhf" architectures (and "all" for some
platform-independent code). This is currently a "testing" variant of
Debian and a moving target in terms of formal support (although seems
recently "frozen" and heading to official stable supported release).
However, automatic dependency handling in OBS should handle refreshed
source code coming from upstream for us.

Automatic setup of OBS as a package source for a supported Debian 8.0
platform with APT package management should work like this (execute
as "root"):
----
:; wget -O - \
     http://obs.roz.lab.etn.com:82/Pool:/master/Debian_8.0/Release.key | \
     apt-key add - && \
   echo 'deb http://obs.roz.lab.etn.com:82/Pool:/master/Debian_8.0 /' > \
     /etc/apt/sources.list.d/95bios-obs-roz-deb8.list
:; wget -O - \
     http://obs.mbt.lab.etn.com:82/Pool:/master/Debian_8.0/Release.key | \
     apt-key add - && \
   echo 'deb http://obs.mbt.lab.etn.com:82/Pool:/master/Debian_8.0 /' > \
     /etc/apt/sources.list.d/95bios-obs-mbt-deb8.list
:; apt-get update
----
Afterwards the usual installation and update actions with `apt-get install`,
search with `apt-cache search` and so on should work.

Manually fetching and installing packages built for Debian 8.0
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
For weird manual installations of our pre-built packages from OBS to
a system similar to Debian-8.0, consider downloading the current
package files into some temporary storage with this script:
----
#!/bin/sh
for DIR in \
    http://obs.roz.lab.etn.com:82/Pool:/master/Debian_8.0/{amd64,all}/ \
; do
    wget -l1 -np -nd -N -c -r --remove-listing --accept=.deb "$DIR"
done
rm -f *.html*
----
Then you can install the packages with `dpkg -i filename.deb`

To fetch the sources used by OBS for a local rebuild, check this out:
----
#!/bin/sh
wget -l1 -np -nd -N -c -r --remove-listing \
    --accept='.dsc,.tar.xz,.tar.gz,.tar.bz2,.tgz,.tbz,.tbz2,.txz' \
    http://obs.roz.lab.etn.com:82/Pool:/master/Debian_8.0/
----



Installation of the build dependencies from packages
----------------------------------------------------
While most of the prerequisite software needed to build or run the $BIOS
core can be compiled more or less easily, the project servers provide
binary packages for most of the needed software which is either absent
or obsolete in original OS repositories.

When installing Debian 8 "testing" packages from OBS as well as from
the upstream OS itself, don't forget to update the metadata index first
(new builds may be available):
----
:; apt-get update
----


iproute (may be named iproute2)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 * Install iproute-dev development files, version "20120521" or newer,
using your configured system repositories, i.e. with Debian APT:
----
:; apt-get install iproute2-dev

### Note that this should fetch the non-empty variant of the package
### from OBS with uotput like this:

Reading package lists... Done
Building dependency tree
Reading state information... Done
The following NEW packages will be installed:
  iproute2-dev
0 upgraded, 1 newly installed, 0 to remove and 310 not upgraded.
Need to get 9,662 B of archives.
After this operation, 64.5 kB of additional disk space will be used.
Get:1 http://obs.roz.lab.etn.com:82/Pool:/master/Debian_8.0/  iproute2-dev 3.16.0-0 [9,662 B]
Fetched 9,662 B in 5s (1,921 B/s)
Selecting previously unselected package iproute2-dev.
(Reading database ... 49826 files and directories currently installed.)
Preparing to unpack .../iproute2-dev_3.16.0-0_amd64.deb ...
Unpacking iproute2-dev (3.16.0-0) ...
Setting up iproute2-dev (3.16.0-0) ...
----
...or with Suse Zypper:
----
:; zypper install libnetlink-devel
----

[NOTE]
======
*TODO*: Which version of iproute *should* be used if building from source --
same release as the current Linux kernel on a given machine? Specific fixed
release? Latest release?)

It seems currently that recent Debian, unlike other distributions, renamed
the 'iproute' package to 'iproute2' and intentionally stripped away its
variant of the 'netlink' library (which our project currently uses, and
which was previously part of 'iproute-dev'). Thus a private build of the
'iproute' software from the sources is needed, and for supported systems
our project provides it in a packaged form. We only need the library (not
the Linux kernel-intimate components), and the API is deemed stable, so
any recent version of 'iproute' should suffice -- the project has been
tested with "20120521" (which is available in Debian wheezy) and that
version is known to work and suffice for us.
======

MariaDB
~~~~~~~
 * Install MariaDB development and product packages from OBS:
----
:; apt-get install libmariadbclient-dev libmariadbd-dev \
   mariadb-server mariadb-client mariadb-test

### Pick the version needed to match the rest of the database,
### the OBS serves 'mariadb-10.0' at the moment of this writing:
:; apt-get install mariadb-connect-engine'*'
----
 ** The 'mariadb-server' installer will ask for the database's 'root'
user new password.

libCIDR and CIDRcalc
~~~~~~~~~~~~~~~~~~~~
 * Install libcidr and related stuff:
----
:; apt-get install cidrcalc libcidr'*'
----
 ** Note that the package-name version is numbered ('libcidr0' and
'libcidr0-dev') at the moment of this writing, which is a bit
inconvenient in the long term documentation support. Things may be
different on your newer system.

TNTNET, TNTDB, CXXTOOLS and friends
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 * Install the TNT project parts:
----
:; apt-get install tntnet tntnet-runtime libcxxtools-dev \
   libtntdb-dev libtntnet-dev libtnt-dev libsasl2-dev
----
 ** Notes: the `cxxtools` or `libcxxtools` package may be absent or differently
named in other OS releases, and may need to be rebuilt from source completely.
 ** The non-"dev" base packages tend to have a version number embedded,
so it is a safer bet to request the "-dev" packages since we need them
anyway, and they will pull in their modern base packages as needed.

Network UPS Tools (NUT)
~~~~~~~~~~~~~~~~~~~~~~~
 * Install NUT project parts needed for linking:
----
:; apt-get install libupsclient-dev libnutclient-dev
----
 ** Note: specifically the $BIOS core project needs 'libnutclient' version
0.27 or newer, which is provided either by recent source of the Network
UPS Tools, or by its very recent packaging (numbered 2.7.2-2 on OBS for
Debian).
 ** If you need more of NUT (actual programs -- drivers, server and client
daemons and utilities), consider adding these packages:
----
:; apt-get install nut-server nut-client nut
----
 ** Installation of 'nut-client' can complain on a `systemd`-controlled OS
like Debian 8, because it tries to start all daemons regardless of their
default configuration files which block startup on SysV-based systems.
As a result, the not-yet-confiugred daemons fail and the package may end
up not-installed. In this case review the errors following hints from the
packaging program and fix the offending files such as '/etc/nut/upsmon.conf'
(set 'MINSUPPLIES 0' where appropriate). The 'nut-server' package can
complain about no configured UPS-monitoring drivers, but this is not fatal.
See https://github.com/networkupstools/nut/issues/156 for more details.

libVariant
~~~~~~~~~~
 * Install libVariant:
----
:; apt-get install libvariant-dev
----

ZeroMQ and friends
~~~~~~~~~~~~~~~~~~
 * Install ZeroMQ and related project parts:
----
:; apt-get install libsodium-dev libzmq3-dev libczmq-dev gsl-bin
----

 * On a rare system used to develop the ZMQ-based protocols involved 
in the $BIOS code project (i.e. almost never) one might need 'zproto'
and 'gsl' programs used to generate the C sources and headers further
used by an application project like $BIOS. Both of these are available
on Git and are easy to compile followint their READMEs, but binary
packages are not generally needed and are not provided. If required,
refer to these projects directly for more details:
 ** https://github.com/zeromq/zproto
 ** https://github.com/imatix/gsl


Configure and build the $BIOS project sources
---------------------------------------------
(Getting the project sources is covered above in this document).

The autogen.sh script
~~~~~~~~~~~~~~~~~~~~~
The project includes an `autogen.sh` script which currently defines the
following methods (selected by first attribute on the command-line):
 * (no attributes) Recreate the `configure` script if needed, and exit
 * 'build' or 'build-samedir' -- (re)create `configure` if needed, run it
in the project root directory, execute a parallel (for speed) and then a
sequential (for correctness) `make` for targets named further on the
command line (or default to 'all' as defined in the 'Makefile')
 * 'build-subdir' -- same as above, except that a subdirectory is created
and changed into before doing the job
 * 'install' or 'install-samedir' -- do the 'build-samedir' routine followed
by a `make install`
 * 'install-subdir' -- do the 'build-subdir' routine followed by
a `make install`
 * 'distcheck' -- (re)create `configure` if needed, run it in the project
root directory, and run `make distcheck`


The short version
~~~~~~~~~~~~~~~~~
If everything goes smoothly, you just need to run this snippet in the
base directory of your source-code checkout (details and explanations
follow in the next chapter) for a (re)build of the $BIOS core codebase:
 * set up the paths (optionally -- the values shown below are the defaults
for the `autogen.sh` script if nothing has been defined by the user):
----
:; BLDARCH="`uname -s`-`uname -m`"
:; DESTDIR=/var/tmp/bios-core-instroot-${BLDARCH}
:; export BLDARCH DESTDIR
----
 * run a (re)build based in the same directory:
----
:; ./autogen.sh build
----
 * optionally, instead run a (re)build based in the same directory and
install the products under 'DESTDIR':
----
:; ./autogen.sh install
----

If this simple build fails, try the longer version step-by-step and with
more verbosity, as detailed below.



The slightly longer version
~~~~~~~~~~~~~~~~~~~~~~~~~~~
Under the hood, the `autogen.sh` script's 'build*' and 'install*' methods
execute logic similar to this:
----
:; BLDARCH="`uname -s`-`uname -m`"
:; ( make -k distclean; \
     ./autogen.sh && \
     ./configure && \
   { make -k clean; make V=0 -j 4 -k all; make all; } && \
   { make DESTDIR=/var/tmp/bios-core-instroot-${BLDARCH} install; } )
----

NOTE: Currently the following pretty subdir-build fails due to `doxygen`,
but the rest works:
----
:; BLDARCH="`uname -s`-`uname -m`"
:; ( ./autogen.sh && \
   { rm -rf build-${BLDARCH}; \
     mkdir build-${BLDARCH}; \
     cd build-${BLDARCH}; } && \
   ../configure && \
   { make V=0 -j 4 -k all; make all; } && \
   { make DESTDIR=/var/tmp/bios-core-instroot-${BLDARCH} install; } )
----

The long version
~~~~~~~~~~~~~~~~

If no `configure` script is available yet (or if it needs to be rebuilt):

 * create or update the `configure` script:
----
:; ./autogen.sh
----
 * ...or if you need to enforce an update of the `configure` script:
----
:; autoreconf -fiv
----

else (if configure script exists and is acceptable):

 * Configure the build system:
----
:; ./configure
----
 ** An "out-of-tree" build (i.e. to produce binaries and other build
    results for different platforms from the same copy of the source
    codebase) can be triggered in a way similar to this:
----
:; mkdir build
:; cd build && \
   ../configure && \
   make
----
 * Build the sources:
----
:; make
----
 ** When the project becomes large enough, it may make sense to speed up
    the builds using parallelization, followed by a pass of sequential
    make to reduce the impact of intemittent failures, such as those
    caused by filesystem lags, out-of-memory issues, or by breaking
    some unspecified dependency ordering. Assuming a GNU `make`, run:
----
:; make -j 4 -k ; make
----
 ** A quieter build can be triggered for GNU `make` with 'V=0' parameter
    (which means that means only 'CC', 'CXX', 'CXXLD' lines will appear -
    which is good at least until you hit some build errors and need more
    verbosity), thus suggesting this command line:
----
:; make V=0 -j 4 -k ; make V=0
----
 * Install the binaries (under a chosen destination root directory
   '/some/path', such as under a temporary filesystem or your homedir):
----
:; make DESTDIR=/some/path install
----


Testing the build
-----------------
The 'Makefile' includes some targets for automated testing, such as

 * `make check` -- this would trigger the compilation of all tests
   (including 'db-tests'), and run all tests except 'db-tests'.
 * `make test-db` -- would trigger the compilation only for database
   tests
 * `./test-db` -- would run the database tests

Note: as part of the project's automated validation the `make distcheck`
must succeed in building and testing all targets, including a subdirectory
build. An `./autogen.sh distcheck` method exists to automate this into a
single-command routine to configure-build-check.
